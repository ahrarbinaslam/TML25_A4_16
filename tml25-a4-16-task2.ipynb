{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **TML Assignment 4 - Task 2**\n\n## **TEAM 16**\n\n## **Ahrar Bin Aslam and Muhammad Mubeen Siddiqui**","metadata":{}},{"cell_type":"markdown","source":"## **Setting Up the Environment and Downloading the Images**","metadata":{}},{"cell_type":"code","source":"import os\nimport requests\n\n# Create output directory\nos.makedirs(\"imagenet_images\", exist_ok=True)\n\n# ImageNet sample image URLs\nimage_urls = {\n    \"West_Highland_white_terrier\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n02098286_West_Highland_white_terrier.JPEG\",\n    \"American_coot\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n02018207_American_coot.JPEG\",\n    \"racer\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n04037443_racer.JPEG\",\n    \"flamingo\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n02007558_flamingo.JPEG\",\n    \"kite\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01608432_kite.JPEG\",\n    \"goldfish\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01443537_goldfish.JPEG\",\n    \"tiger_shark\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01491361_tiger_shark.JPEG\",\n    \"vulture\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01616318_vulture.JPEG\",\n    \"common_iguana\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01677366_common_iguana.JPEG\",\n    \"orange\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n07747607_orange.JPEG\",\n}\n\n# Download images\nfor name, url in image_urls.items():\n    filename = f\"imagenet_images/{name}.jpeg\"\n    if not os.path.exists(filename):\n        print(f\"Downloading {name}...\")\n        response = requests.get(url)\n        with open(filename, 'wb') as f:\n            f.write(response.content)\nprint(\"All images downloaded successfully.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T22:26:11.425515Z","iopub.execute_input":"2025-07-20T22:26:11.425791Z","iopub.status.idle":"2025-07-20T22:26:12.495578Z","shell.execute_reply.started":"2025-07-20T22:26:11.425769Z","shell.execute_reply":"2025-07-20T22:26:12.494878Z"}},"outputs":[{"name":"stdout","text":"Downloading West_Highland_white_terrier...\nDownloading American_coot...\nDownloading racer...\nDownloading flamingo...\nDownloading kite...\nDownloading goldfish...\nDownloading tiger_shark...\nDownloading vulture...\nDownloading common_iguana...\nDownloading orange...\nAll images downloaded successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## **Installing Grad-CAM**","metadata":{}},{"cell_type":"code","source":"!pip install grad-cam -q\nfrom pytorch_grad_cam import GradCAM\nprint(\"Grad-CAM installed successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T22:26:13.885341Z","iopub.execute_input":"2025-07-20T22:26:13.885606Z","iopub.status.idle":"2025-07-20T22:27:41.391683Z","shell.execute_reply.started":"2025-07-20T22:26:13.885584Z","shell.execute_reply":"2025-07-20T22:27:41.390857Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Building wheel for grad-cam (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nGrad-CAM installed successfully!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## **Installing Dependencies**","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport torch\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nfrom pytorch_grad_cam import GradCAM, ScoreCAM, AblationCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T22:27:41.393075Z","iopub.execute_input":"2025-07-20T22:27:41.393502Z","iopub.status.idle":"2025-07-20T22:27:41.397465Z","shell.execute_reply.started":"2025-07-20T22:27:41.393472Z","shell.execute_reply":"2025-07-20T22:27:41.396699Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## **Load and Prepare Pretrained ResNet50 Model for Inference**","metadata":{}},{"cell_type":"code","source":"model = models.resnet50(pretrained=True)\nmodel.eval()\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T22:27:41.398150Z","iopub.execute_input":"2025-07-20T22:27:41.398450Z","iopub.status.idle":"2025-07-20T22:27:42.834640Z","shell.execute_reply.started":"2025-07-20T22:27:41.398414Z","shell.execute_reply":"2025-07-20T22:27:42.833875Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 196MB/s] \n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## **Grad-CAM, AblationCAM, and ScoreCAM**","metadata":{}},{"cell_type":"code","source":"output_dir = \"cam_outputs\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Last conv layer for ResNet50\ntarget_layer = model.layer4[-1]\n\n# Loop through each image\nfor name in image_urls:\n    img_path = f\"imagenet_images/{name}.jpeg\"\n    image = Image.open(img_path).convert('RGB')\n\n    # Preprocess image\n    input_tensor = transform(image).unsqueeze(0).to(device)\n    resized_image = transforms.Resize((224, 224))(image)\n    rgb_image_np = transforms.ToTensor()(resized_image).permute(1, 2, 0).numpy()\n    rgb_image_np = rgb_image_np / rgb_image_np.max()\n\n    # Predict class\n    with torch.no_grad():\n        output = model(input_tensor)\n        class_idx = output.argmax().item()\n    targets = [ClassifierOutputTarget(class_idx)]\n\n    # Grad-CAM\n    grad_cam = GradCAM(model=model, target_layers=[target_layer])\n    cam_map = grad_cam(input_tensor=input_tensor, targets=targets)[0]\n    gradcam_vis = show_cam_on_image(rgb_image_np, cam_map, use_rgb=True)\n    del grad_cam\n\n    # AblationCAM\n    ablation_cam = AblationCAM(model=model, target_layers=[target_layer])\n    cam_map = ablation_cam(input_tensor=input_tensor, targets=targets)[0]\n    ablation_vis = show_cam_on_image(rgb_image_np, cam_map, use_rgb=True)\n    del ablation_cam\n\n    # ScoreCAM\n    score_cam = ScoreCAM(model=model, target_layers=[target_layer])\n    cam_map = score_cam(input_tensor=input_tensor, targets=targets)[0]\n    score_vis = show_cam_on_image(rgb_image_np, cam_map, use_rgb=True)\n    del score_cam\n\n    # Plot and save\n    plt.figure(figsize=(12, 4))\n    plt.suptitle(f\"{name}\", fontsize=14)\n\n    plt.subplot(1, 4, 1)\n    plt.imshow(image)\n    plt.axis('off')\n    plt.title(\"Original\")\n\n    plt.subplot(1, 4, 2)\n    plt.imshow(gradcam_vis)\n    plt.axis('off')\n    plt.title(\"Grad-CAM\")\n\n    plt.subplot(1, 4, 3)\n    plt.imshow(ablation_vis)\n    plt.axis('off')\n    plt.title(\"AblationCAM\")\n\n    plt.subplot(1, 4, 4)\n    plt.imshow(score_vis)\n    plt.axis('off')\n    plt.title(\"ScoreCAM\")\n\n    plt.tight_layout()\n    plt.savefig(f\"{output_dir}/{name}_cams.png\")\n    plt.close()\n    print(f\"Saved: {output_dir}/{name}_cams.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-20T22:27:42.835849Z","iopub.execute_input":"2025-07-20T22:27:42.836075Z","iopub.status.idle":"2025-07-20T22:29:58.069099Z","shell.execute_reply.started":"2025-07-20T22:27:42.836058Z","shell.execute_reply":"2025-07-20T22:29:58.068115Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 64/64 [00:05<00:00, 11.74it/s]\n100%|██████████| 128/128 [00:06<00:00, 20.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/West_Highland_white_terrier_cams.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:05<00:00, 11.64it/s]\n100%|██████████| 128/128 [00:05<00:00, 21.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/American_coot_cams.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:05<00:00, 11.37it/s]\n100%|██████████| 128/128 [00:06<00:00, 20.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/racer_cams.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:05<00:00, 11.08it/s]\n100%|██████████| 128/128 [00:06<00:00, 20.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/flamingo_cams.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:05<00:00, 10.75it/s]\n100%|██████████| 128/128 [00:06<00:00, 19.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/kite_cams.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:06<00:00, 10.11it/s]\n100%|██████████| 128/128 [00:06<00:00, 18.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/goldfish_cams.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:06<00:00,  9.44it/s]\n100%|██████████| 128/128 [00:07<00:00, 17.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/tiger_shark_cams.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:07<00:00,  8.77it/s]\n100%|██████████| 128/128 [00:07<00:00, 16.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/vulture_cams.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:06<00:00,  9.19it/s]\n100%|██████████| 128/128 [00:07<00:00, 17.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/common_iguana_cams.png\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 64/64 [00:06<00:00,  9.71it/s]\n100%|██████████| 128/128 [00:06<00:00, 18.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saved: cam_outputs/orange_cams.png\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
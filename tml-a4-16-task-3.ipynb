{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **TML Assignment 4 - Task 3** ##","metadata":{}},{"cell_type":"markdown","source":"## **Ahrar Bin Aslam and Muhammad Mubeen Siddiqui**","metadata":{}},{"cell_type":"markdown","source":"## Installing Lime","metadata":{}},{"cell_type":"code","source":"!pip install lime --q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:41:38.169808Z","iopub.execute_input":"2025-07-23T08:41:38.169970Z","iopub.status.idle":"2025-07-23T08:41:42.808433Z","shell.execute_reply.started":"2025-07-23T08:41:38.169954Z","shell.execute_reply":"2025-07-23T08:41:42.807275Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Importing Libraries and Setup","metadata":{}},{"cell_type":"code","source":"import os\nimport requests\nimport numpy as np\nimport torch\nimport torchvision.models as models\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom lime import lime_image\nfrom skimage.segmentation import mark_boundaries\nfrom lime.wrappers.scikit_image import SegmentationAlgorithm\nfrom sklearn.linear_model import Ridge\nimport pickle\n\n# Setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nos.makedirs(\"imagenet_images\", exist_ok=True)\nos.makedirs(\"lime_outputs\", exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Downloading Images","metadata":{}},{"cell_type":"code","source":"# Image URLs\nimage_urls = {\n    \"West_Highland_white_terrier\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n02098286_West_Highland_white_terrier.JPEG\",\n    \"American_coot\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n02018207_American_coot.JPEG\",\n    \"racer\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n04037443_racer.JPEG\",\n    \"flamingo\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n02007558_flamingo.JPEG\",\n    \"kite\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01608432_kite.JPEG\",\n    \"goldfish\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01443537_goldfish.JPEG\",\n    \"tiger_shark\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01491361_tiger_shark.JPEG\",\n    \"vulture\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01616318_vulture.JPEG\",\n    \"common_iguana\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n01677366_common_iguana.JPEG\",\n    \"orange\": \"https://raw.githubusercontent.com/EliSchwartz/imagenet-sample-images/master/n07747607_orange.JPEG\",\n}\n\n# Download images\nfor name, url in image_urls.items():\n    path = f\"imagenet_images/{name}.jpeg\"\n    if not os.path.exists(path):\n        r = requests.get(url)\n        with open(path, 'wb') as f:\n            f.write(r.content)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading the Model and Image Transforms","metadata":{}},{"cell_type":"code","source":"# Load model\nmodel = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\nmodel.eval().to(device)\n\n# Transforms\ndef transform_for_lime(img):\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n    ])\n    return transform(img).permute(1, 2, 0).numpy()\n\npreprocess = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Classifier for LIME","metadata":{}},{"cell_type":"code","source":"# Batch classifier\ndef batch_predict(images):\n    processed = []\n    for img in images:\n        if img.dtype != np.uint8:\n            img = (img * 255).astype(np.uint8)\n\n        if img.shape[0] == 1 and img.shape[1] == 1 and img.shape[2] == 3:\n            img = np.tile(img, (224, 224, 1))  # if somehow super small\n\n        img_pil = Image.fromarray(img)\n        tensor = preprocess(img_pil)\n        processed.append(tensor)\n\n    batch = torch.stack(processed, dim=0).to(device)\n    with torch.no_grad():\n        logits = model(batch)\n    return torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n\n# Init explainer\nexplainer = lime_image.LimeImageExplainer()\nlime_params_dict = {}\n\n# Loop through images\nfor name in image_urls:\n    print(f\"Explaining: {name}\")\n    img_path = f\"imagenet_images/{name}.jpeg\"\n    pil_img = Image.open(img_path).convert('RGB')\n    img_np = transform_for_lime(pil_img)\n\n    # Get top predicted class\n    input_tensor = preprocess(pil_img).unsqueeze(0).to(device)\n    with torch.no_grad():\n        pred = model(input_tensor)\n    top_label = int(pred.argmax().item())\n\n    hide_color = np.quantile(img_np, 0.2, axis=(0, 1)).astype(int).tolist()\n\n    # Segmentation\n    segmentation_fn = SegmentationAlgorithm(\n        'quickshift',\n        kernel_size=5,\n        max_dist=150,\n        ratio=0.3\n    )\n\n    # Run Lime Explainer\n    explanation = explainer.explain_instance(\n        img_np,\n        classifier_fn=batch_predict,\n        labels=(top_label,),\n        top_labels=1,\n        num_features=12,             \n        num_samples=700,              \n        batch_size=10,\n        segmentation_fn=segmentation_fn,\n        distance_metric='cosine',\n        model_regressor=Ridge(alpha=0.5),\n        random_seed=42,\n        hide_color=hide_color\n    )\n\n    # Visualize explanation\n    temp, mask = explanation.get_image_and_mask(\n        label=top_label,\n        positive_only=True,\n        num_features=10,\n        hide_rest=False\n    )\n\n    temp_uint8 = (temp * 255).astype(np.uint8) if temp.dtype != np.uint8 else temp\n    output_img = mark_boundaries(temp_uint8, mask)\n\n    plt.figure(figsize=(6, 6))\n    plt.imshow(output_img)\n    plt.axis('off')\n    plt.title(f\"LIME - {name}\")\n    plt.tight_layout()\n    plt.savefig(f\"lime_outputs/{name}_lime.png\")\n    plt.close()\n\n    # Save params for Deliverable 4\n    lime_params_dict[name] = {\n        'labels': (top_label,),\n        'hide_color': hide_color,\n        'top_labels': 1,\n        'num_features': 12,\n        'num_samples': 700,\n        'batch_size': 10,\n        'segmentation_fn': segmentation_fn,\n        'distance_metric': 'cosine',\n        'model_regressor': Ridge(alpha=0.5),\n        'random_seed': 42\n    }\n\n# Save the dictionary as pickle for submission\nwith open(\"lime_params.pkl\", \"wb\") as f:\n    pickle.dump(lime_params_dict, f)\n\nprint(\"LIME visualizations and lime_params.pkl created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:49:20.206413Z","iopub.execute_input":"2025-07-23T08:49:20.207089Z","iopub.status.idle":"2025-07-23T08:50:15.959204Z","shell.execute_reply.started":"2025-07-23T08:49:20.207065Z","shell.execute_reply":"2025-07-23T08:50:15.958387Z"}},"outputs":[{"name":"stdout","text":"Explaining: West_Highland_white_terrier\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20f5e25357b64839a2c79c87ffc5fd87"}},"metadata":{}},{"name":"stdout","text":"Explaining: American_coot\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7703a90fecd424191a52a6fbcc8457d"}},"metadata":{}},{"name":"stdout","text":"Explaining: racer\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f41e075da2c4e89976c3c3615f51977"}},"metadata":{}},{"name":"stdout","text":"Explaining: flamingo\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5ae7f4d58494689944c65680509dbed"}},"metadata":{}},{"name":"stdout","text":"Explaining: kite\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00f15a1f07aa421a8f50291d5f4efd14"}},"metadata":{}},{"name":"stdout","text":"Explaining: goldfish\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ffc6b49033a40a49ab9cbc49b873e30"}},"metadata":{}},{"name":"stdout","text":"Explaining: tiger_shark\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b01fc0ba41b349b69f8e2923c27753de"}},"metadata":{}},{"name":"stdout","text":"Explaining: vulture\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa632f0ffd4142d68fb4875a2fb53e8e"}},"metadata":{}},{"name":"stdout","text":"Explaining: common_iguana\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ad7dfee311a4563bcadd2ca30404dd0"}},"metadata":{}},{"name":"stdout","text":"Explaining: orange\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"651290d4ea1e49559526c8bac25efc16"}},"metadata":{}},{"name":"stdout","text":"LIME visualizations and lime_params.pkl created successfully.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import requests\n\n# Path to your .pkl file (generated from your script)\nfile_path = \"lime_params.pkl\"\n\n# Your provided token\ntoken = \"93145372\"\n\n# Submit to server\nresponse = requests.post(\n    \"http://34.122.51.94:9091/lime\",\n    files={\"file\": open(file_path, \"rb\")},\n    headers={\"token\": token}\n)\n\n# Print server response\nprint(response.json())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T08:51:17.616991Z","iopub.execute_input":"2025-07-23T08:51:17.617704Z","iopub.status.idle":"2025-07-23T08:51:51.317552Z","shell.execute_reply.started":"2025-07-23T08:51:17.617677Z","shell.execute_reply":"2025-07-23T08:51:51.316844Z"}},"outputs":[{"name":"stdout","text":"{'avg_iou': 0.3206986647682452, 'avg_time': 3.362541437149048}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}